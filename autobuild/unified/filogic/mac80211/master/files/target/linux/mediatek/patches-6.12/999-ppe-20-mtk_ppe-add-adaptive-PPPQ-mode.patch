From 6fb6034cfbb152c3355017b9d3b09f27e6d7f4c1 Mon Sep 17 00:00:00 2001
From: Bo-Cun Chen <bc-bocun.chen@mediatek.com>
Date: Wed, 24 Sep 2025 12:59:26 +0800
Subject: [PATCH] net: ethernet: mtk_ppe: add adaptive PPPQ mode

User can use the commnad below to enable adaptive PPPQ mode.
  - echo 3 > /sys/kernel/debug/mtk_ppe/qos_toggle

This mode can control the total number of PPPQ users to ensure they
do not exceed the QDMA bandwidth.

Signed-off-by: Bo-Cun Chen <bc-bocun.chen@mediatek.com>
---
 drivers/net/ethernet/mediatek/mtk_eth_soc.h   |  5 +++
 drivers/net/ethernet/mediatek/mtk_ppe.c       | 33 +++++++++++++++++--
 drivers/net/ethernet/mediatek/mtk_ppe.h       |  1 +
 .../net/ethernet/mediatek/mtk_ppe_debugfs.c   |  7 ++++
 .../net/ethernet/mediatek/mtk_ppe_offload.c   |  2 +-
 5 files changed, 45 insertions(+), 3 deletions(-)

diff --git a/drivers/net/ethernet/mediatek/mtk_eth_soc.h b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
index 5d07e3d..28de173 100644
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.h
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
@@ -1923,6 +1923,11 @@ mtk_ppe_check_pppq_path(struct mtk_mac *mac, struct net_device *idev, int dsa_po
 	    (dsa_port == 5 && wifi_rx))
 		return 1;
 
+	if (mtk_is_netsys_v3_or_greater(mac->hw)) {
+		if (mac->hw->qos_toggle == 3 && mac->speed <= SPEED_2500 && wifi_rx)
+			return 1;
+	}
+
 	return 0;
 }
 
diff --git a/drivers/net/ethernet/mediatek/mtk_ppe.c b/drivers/net/ethernet/mediatek/mtk_ppe.c
index 67c93d3..053bb30 100644
--- a/drivers/net/ethernet/mediatek/mtk_ppe.c
+++ b/drivers/net/ethernet/mediatek/mtk_ppe.c
@@ -718,16 +718,29 @@ __mtk_foe_entry_clear(struct mtk_ppe *ppe, struct mtk_flow_entry *entry,
 
 	if (entry->hash != 0xffff && set_state) {
 		struct mtk_foe_entry *hwe = mtk_foe_get_entry(ppe, entry->hash);
+		int queue;
+		u32 *ib2;
 
 		state = FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1);
 
+		if (mtk_is_netsys_v3_or_greater(ppe->eth) && ppe->eth->qos_toggle == 3) {
+			ib2 = mtk_foe_entry_ib2(ppe->eth, &entry->data);
+			if (*ib2 & MTK_FOE_IB2_PSE_QOS_V2) {
+				queue = mtk_foe_entry_get_queue(ppe->eth, &entry->data);
+				spin_lock(&ppe->eth->qdma_shaper.lock);
+				mtk_shaper_update_refcnt(ppe->eth, queue, false);
+				spin_unlock(&ppe->eth->qdma_shaper.lock);
+			}
+		}
+
 		hwe->ib1 &= ~MTK_FOE_IB1_STATE;
 		hwe->ib1 |= FIELD_PREP(MTK_FOE_IB1_STATE, MTK_FOE_STATE_INVALID);
 		dma_wmb();
 		if (state == MTK_FOE_STATE_BIND)
 			mtk_ppe_cache_clear(ppe);
+
+		entry->hash = 0xffff;
 	}
-	entry->hash = 0xffff;
 
 	if (entry->type != MTK_FLOW_TYPE_L2_SUBFLOW)
 		return;
@@ -848,7 +861,8 @@ __mtk_foe_entry_commit(struct mtk_ppe *ppe, struct mtk_foe_entry *entry,
 	struct mtk_eth *eth = ppe->eth;
 	u16 timestamp = mtk_eth_timestamp(eth);
 	struct mtk_foe_entry *hwe;
-	u32 val;
+	u32 val, *ib2;
+	int queue;
 
 	hwe = mtk_foe_get_entry(ppe, hash);
 
@@ -865,6 +879,21 @@ __mtk_foe_entry_commit(struct mtk_ppe *ppe, struct mtk_foe_entry *entry,
 					 timestamp);
 	}
 
+	if (mtk_is_netsys_v3_or_greater(ppe->eth) && ppe->eth->qos_toggle == 3) {
+		ib2 = mtk_foe_entry_ib2(ppe->eth, entry);
+		if (*ib2 & MTK_FOE_IB2_PSE_QOS_V2) {
+			queue = mtk_foe_entry_get_queue(ppe->eth, entry);
+			spin_lock(&ppe->eth->qdma_shaper.lock);
+			if (mtk_shaper_is_available(ppe->eth, queue))
+				mtk_shaper_update_refcnt(ppe->eth, queue, true);
+			else {
+				/* Switch back to non-shaper path */
+				*ib2 &= ~(MTK_FOE_IB2_PSE_QOS_V2 | MTK_FOE_IB2_QID_V2);
+			}
+			spin_unlock(&ppe->eth->qdma_shaper.lock);
+		}
+	}
+
 	memcpy(&hwe->data, &entry->data, eth->soc->foe_entry_size - sizeof(hwe->ib1));
 	wmb();
 	hwe->ib1 = entry->ib1;
diff --git a/drivers/net/ethernet/mediatek/mtk_ppe.h b/drivers/net/ethernet/mediatek/mtk_ppe.h
index cca64f7..2ecf448 100644
--- a/drivers/net/ethernet/mediatek/mtk_ppe.h
+++ b/drivers/net/ethernet/mediatek/mtk_ppe.h
@@ -379,6 +379,7 @@ mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)
 	__mtk_ppe_check_skb(ppe, skb, hash);
 }
 
+unsigned int mtk_foe_entry_get_queue(struct mtk_eth *eth, struct mtk_foe_entry *entry);
 int mtk_foe_entry_prepare(struct mtk_eth *eth, struct mtk_foe_entry *entry,
 			  int type, int l4proto, u8 pse_port, u8 *src_mac,
 			  u8 *dest_mac);
diff --git a/drivers/net/ethernet/mediatek/mtk_ppe_debugfs.c b/drivers/net/ethernet/mediatek/mtk_ppe_debugfs.c
index a45c3d7..78fd523 100644
--- a/drivers/net/ethernet/mediatek/mtk_ppe_debugfs.c
+++ b/drivers/net/ethernet/mediatek/mtk_ppe_debugfs.c
@@ -207,6 +207,8 @@ mtk_ppe_internal_debugfs_read_qos(struct seq_file *m, void *private)
 		pr_info("HQoS is enabled now!\n");
 	else if (eth->qos_toggle == 2)
 		pr_info("Per-port-per-queue mode is enabled!\n");
+	else if (eth->qos_toggle == 3)
+		pr_info("Adaptive Per-port-per-queue mode is enabled!\n");
 
 	return 0;
 }
@@ -239,6 +241,11 @@ mtk_ppe_internal_debugfs_write_qos(struct file *file, const char __user *buffer,
 		pr_info("Per-port-per-queue mode is going to be enabled !\n");
 		pr_info("PPPQ use qid 3~14 (scheduler 0).\n");
 		eth->qos_toggle = 2;
+	} else if (buf[0] == '3') {
+		pr_info("Adaptive Per-port-per-queue mode is going to be enabled !\n");
+		pr_info("PPPQ use qid 3~14 (scheduler 0).\n");
+		eth->qos_toggle = 3;
+		eth->qdma_shaper.threshold = 6000;
 	}
 
 	return len;
diff --git a/drivers/net/ethernet/mediatek/mtk_ppe_offload.c b/drivers/net/ethernet/mediatek/mtk_ppe_offload.c
index 000b56a..47086cb 100644
--- a/drivers/net/ethernet/mediatek/mtk_ppe_offload.c
+++ b/drivers/net/ethernet/mediatek/mtk_ppe_offload.c
@@ -334,7 +334,7 @@ mtk_flow_set_output_device(struct mtk_eth *eth, struct mtk_foe_entry *foe,
 		ct_mark = ct->mark;
 	}
 
-	if (eth->qos_toggle == 2 && mtk_ppe_check_pppq_path(mac, idev, dsa_port)) {
+	if ((eth->qos_toggle == 2 || eth->qos_toggle == 3) && mtk_ppe_check_pppq_path(mac, idev, dsa_port)) {
 		if ((dsa_port >= 0) && ct && nf_ct_protonum(ct) == IPPROTO_TCP) {
 			/* Dispatch the IPv4/IPv6 TCP Ack packets to the high-priority
 			 * queue, assuming they are less than 64 bytes.
-- 
2.45.2

