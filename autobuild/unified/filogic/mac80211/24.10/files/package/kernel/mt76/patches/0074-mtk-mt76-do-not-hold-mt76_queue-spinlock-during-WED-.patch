From d8c4ed4688c7bd90a11e9592ae6b6d86ef64776e Mon Sep 17 00:00:00 2001
From: Shayne Chen <shayne.chen@mediatek.com>
Date: Thu, 9 Jan 2025 00:02:42 +0800
Subject: [PATCH 74/75] mtk: mt76: do not hold mt76_queue spinlock during WED
 dma init

During dma init or reset stage, rx napi is disabled, so there's no need to
hold the spinlock while doing queue init, which is also time-consuming.
Change to use the corresponding lock-free API.

Signed-off-by: Shayne Chen <shayne.chen@mediatek.com>
---
 dma.c | 7 +++----
 dma.h | 2 ++
 wed.c | 4 ++--
 3 files changed, 7 insertions(+), 6 deletions(-)

diff --git a/dma.c b/dma.c
index 56f0fd4b..9004aa1b 100644
--- a/dma.c
+++ b/dma.c
@@ -748,9 +748,8 @@ free_skb:
 	return ret;
 }
 
-static int
-mt76_dma_rx_fill_buf(struct mt76_dev *dev, struct mt76_queue *q,
-		     bool allow_direct)
+int mt76_dma_rx_fill_buf(struct mt76_dev *dev, struct mt76_queue *q,
+			 bool allow_direct)
 {
 	int len = SKB_WITH_OVERHEAD(q->buf_size);
 	int frames = 0;
@@ -1088,7 +1087,7 @@ __mt76_dma_init(struct mt76_dev *dev, enum mt76_rxq_id qid,
 
 	if (qid < __MT_RXQ_MAX && dev->q_rx[qid].ndesc) {
 		netif_napi_add(&dev->napi_dev, &dev->napi[qid], poll);
-		mt76_dma_rx_fill(dev, &dev->q_rx[qid], false);
+		mt76_dma_rx_fill_buf(dev, &dev->q_rx[qid], false);
 		napi_enable(&dev->napi[qid]);
 		return 0;
 	}
diff --git a/dma.h b/dma.h
index 393be98a..b8906f9d 100644
--- a/dma.h
+++ b/dma.h
@@ -85,6 +85,8 @@ void mt76_dma_attach(struct mt76_dev *dev);
 void mt76_dma_cleanup(struct mt76_dev *dev);
 int mt76_dma_rx_fill(struct mt76_dev *dev, struct mt76_queue *q,
 		     bool allow_direct);
+int mt76_dma_rx_fill_buf(struct mt76_dev *dev, struct mt76_queue *q,
+			 bool allow_direct);
 void __mt76_dma_queue_reset(struct mt76_dev *dev, struct mt76_queue *q,
 			    bool reset_idx);
 void mt76_dma_queue_reset(struct mt76_dev *dev, struct mt76_queue *q, bool reset);
diff --git a/wed.c b/wed.c
index 394ef184..b6eaffe4 100644
--- a/wed.c
+++ b/wed.c
@@ -150,7 +150,7 @@ int mt76_wed_dma_setup(struct mt76_dev *dev, struct mt76_queue *q, bool reset)
 		/* WED txfree queue needs ring to be initialized before setup */
 		q->flags = 0;
 		mt76_dma_queue_reset(dev, q, true);
-		mt76_dma_rx_fill(dev, q, false);
+		mt76_dma_rx_fill_buf(dev, q, false);
 
 		ret = mtk_wed_device_txfree_ring_setup(q->wed, q->regs);
 		if (!ret)
@@ -179,7 +179,7 @@ int mt76_wed_dma_setup(struct mt76_dev *dev, struct mt76_queue *q, bool reset)
 	case MT76_WED_RRO_Q_IND:
 		q->flags &= ~MT_QFLAG_WED;
 		mt76_dma_queue_reset(dev, q, true);
-		mt76_dma_rx_fill(dev, q, false);
+		mt76_dma_rx_fill_buf(dev, q, false);
 		mtk_wed_device_ind_rx_ring_setup(q->wed, q->regs);
 		break;
 	default:
-- 
2.45.2

