From 6256c16718965a43d96b303b7ae2a80a512a9c03 Mon Sep 17 00:00:00 2001
From: Bo-Cun Chen <bc-bocun.chen@mediatek.com>
Date: Wed, 26 Mar 2025 13:19:00 +0800
Subject: [PATCH] net: ethernet: mtk_eth_soc: add GLO_MEM support for lro

Without this patch, the users cannot enable HW_LRO feature on the
mt7987.

Signed-off-by: Bo-Cun Chen <bc-bocun.chen@mediatek.com>
---
 drivers/net/ethernet/mediatek/mtk_eth_soc.c | 176 ++++++++++++++++----
 drivers/net/ethernet/mediatek/mtk_eth_soc.h |  45 ++++-
 2 files changed, 187 insertions(+), 34 deletions(-)

diff --git a/drivers/net/ethernet/mediatek/mtk_eth_soc.c b/drivers/net/ethernet/mediatek/mtk_eth_soc.c
index 099cc27..36ee28b 100644
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.c
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.c
@@ -3106,6 +3106,47 @@ static void mtk_rx_clean(struct mtk_eth *eth, struct mtk_rx_ring *ring, bool in_
 	}
 }
 
+static void mtk_hwlro_cfg_mem_clear(struct mtk_eth *eth)
+{
+	int i;
+
+	if (!MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS))
+		return;
+
+	mtk_w32(eth, 0, MTK_GLO_MEM_CTRL);
+	for (i = 0; i < 10; i++)
+		mtk_w32(eth, 0, MTK_GLO_MEM_DATA(i));
+}
+
+static int mtk_hwlro_cfg_mem_done(struct mtk_eth *eth)
+{
+	u32 val;
+	int ret;
+
+	if (!MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS))
+		return -EPERM;
+
+	ret = readx_poll_timeout_atomic(__raw_readl, eth->base + MTK_GLO_MEM_CTRL,
+					val, !(val & MTK_GLO_MEM_CMD),
+					1000, 1000000);
+	if (ret)
+		dev_err(eth->dev, "GLO_MEM read/write timeout\n");
+
+	return ret;
+}
+
+static u32 mtk_hwlro_cfg_mem_get_dip(struct mtk_eth *eth, u32 index)
+{
+	u32 reg_val;
+
+	reg_val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+	reg_val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_DIP_BASE + index);
+	reg_val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_READ);
+	mtk_w32(eth, reg_val, MTK_GLO_MEM_CTRL);
+
+	return mtk_r32(eth, MTK_GLO_MEM_DATA(0));
+}
+
 static int mtk_hwlro_rx_init(struct mtk_eth *eth)
 {
 	const struct mtk_reg_map *reg_map = eth->soc->reg_map;
@@ -3114,27 +3155,49 @@ static int mtk_hwlro_rx_init(struct mtk_eth *eth)
 	u32 ring_ctrl_dw1 = 0, ring_ctrl_dw2 = 0, ring_ctrl_dw3 = 0;
 	u32 lro_ctrl_dw0 = 0, lro_ctrl_dw3 = 0;
 
-	/* set LRO rings to auto-learn modes */
-	ring_ctrl_dw2 |= MTK_RING_AUTO_LERAN_MODE;
+	if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS)) {
+		for (i = 1; i <= MTK_HW_LRO_RING_NUM; i++) {
+			/* set AGG timer (unit: 20us) */
+			val = FIELD_PREP(MTK_RING_MAX_AGG_TIME_V2, MTK_HW_LRO_AGG_TIME);
+			/* set AGE timer (unit: 20us) */
+			val |= FIELD_PREP(MTK_RING_AGE_TIME, MTK_HW_LRO_AGE_TIME);
+			mtk_w32(eth, val, MTK_GLO_MEM_DATA(0));
+
+			/* set max aggregation count */
+			val = FIELD_PREP(MTK_RING_MAX_AGG_CNT, MTK_HW_LRO_MAX_AGG_CNT);
+			/* set LRO rings to auto-learn modes */
+			val |= FIELD_PREP(MTK_RING_OPMODE, MTK_RING_AUTO_LERAN_MODE_V2);
+			mtk_w32(eth, val, MTK_GLO_MEM_DATA(1));
+
+			val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+			val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_CFG_BASE + i);
+			val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_WRITE);
+			mtk_w32(eth, val, MTK_GLO_MEM_CTRL);
+			mtk_hwlro_cfg_mem_done(eth);
+		}
+	} else {
+		/* set LRO rings to auto-learn modes */
+		ring_ctrl_dw2 |= MTK_RING_AUTO_LERAN_MODE;
 
-	/* validate LRO ring */
-	ring_ctrl_dw2 |= MTK_RING_VLD;
+		/* validate LRO ring */
+		ring_ctrl_dw2 |= MTK_RING_VLD;
 
-	/* set AGE timer (unit: 20us) */
-	ring_ctrl_dw2 |= MTK_RING_AGE_TIME_H;
-	ring_ctrl_dw1 |= MTK_RING_AGE_TIME_L;
+		/* set AGE timer (unit: 20us) */
+		ring_ctrl_dw2 |= MTK_RING_AGE_TIME_H;
+		ring_ctrl_dw1 |= MTK_RING_AGE_TIME_L;
 
-	/* set max AGG timer (unit: 20us) */
-	ring_ctrl_dw2 |= MTK_RING_MAX_AGG_TIME;
+		/* set max AGG timer (unit: 20us) */
+		ring_ctrl_dw2 |= MTK_RING_MAX_AGG_TIME;
 
-	/* set max LRO AGG count */
-	ring_ctrl_dw2 |= MTK_RING_MAX_AGG_CNT_L;
-	ring_ctrl_dw3 |= MTK_RING_MAX_AGG_CNT_H;
+		/* set max LRO AGG count */
+		ring_ctrl_dw2 |= MTK_RING_MAX_AGG_CNT_L;
+		ring_ctrl_dw3 |= MTK_RING_MAX_AGG_CNT_H;
 
-	for (i = 1; i <= MTK_HW_LRO_RING_NUM; i++) {
-		mtk_w32(eth, ring_ctrl_dw1, MTK_LRO_CTRL_DW1_CFG(i));
-		mtk_w32(eth, ring_ctrl_dw2, MTK_LRO_CTRL_DW2_CFG(i));
-		mtk_w32(eth, ring_ctrl_dw3, MTK_LRO_CTRL_DW3_CFG(i));
+		for (i = 1; i <= MTK_HW_LRO_RING_NUM; i++) {
+			mtk_w32(eth, ring_ctrl_dw1, MTK_LRO_CTRL_DW1_CFG(i));
+			mtk_w32(eth, ring_ctrl_dw2, MTK_LRO_CTRL_DW2_CFG(i));
+			mtk_w32(eth, ring_ctrl_dw3, MTK_LRO_CTRL_DW3_CFG(i));
+		}
 	}
 
 	/* IPv4 checksum update enable */
@@ -3212,8 +3275,17 @@ static void mtk_hwlro_rx_uninit(struct mtk_eth *eth)
 	}
 
 	/* invalidate lro rings */
-	for (i = 1; i <= MTK_HW_LRO_RING_NUM; i++)
-		mtk_w32(eth, 0, MTK_LRO_CTRL_DW2_CFG(i));
+	for (i = 1; i <= MTK_HW_LRO_RING_NUM; i++) {
+		if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS)) {
+			mtk_hwlro_cfg_mem_clear(eth);
+			val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+			val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_CFG_BASE + i);
+			val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_WRITE);
+			mtk_w32(eth, val, MTK_GLO_MEM_CTRL);
+			mtk_hwlro_cfg_mem_done(eth);
+		} else
+			mtk_w32(eth, 0, MTK_LRO_CTRL_DW2_CFG(i));
+	}
 
 	/* disable HW LRO */
 	mtk_w32(eth, 0, MTK_PDMA_LRO_CTRL_DW0);
@@ -3224,15 +3296,36 @@ static void mtk_hwlro_val_ipaddr(struct mtk_eth *eth, int idx, __be32 ip)
 	const struct mtk_reg_map *reg_map = eth->soc->reg_map;
 	u32 reg_val;
 
-	reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(idx));
+	if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS)) {
+		/* invalidate the IP setting */
+		reg_val = FIELD_PREP(MTK_LRO_DIP_MODE, MTK_LRO_DIP_INVALID);
+		mtk_w32(eth, reg_val, MTK_GLO_MEM_DATA(4));
+		reg_val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_DIP_BASE + idx);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_WRITE);
+		mtk_w32(eth, reg_val, MTK_GLO_MEM_CTRL);
+		mtk_hwlro_cfg_mem_done(eth);
+
+		/* validate the IP setting */
+		mtk_w32(eth, ip, MTK_GLO_MEM_DATA(0));
+		reg_val = FIELD_PREP(MTK_LRO_DIP_MODE, MTK_LRO_DIP_IPV4);
+		mtk_w32(eth, reg_val, MTK_GLO_MEM_DATA(4));
+		reg_val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_DIP_BASE + idx);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_WRITE);
+		mtk_w32(eth, reg_val, MTK_GLO_MEM_CTRL);
+		mtk_hwlro_cfg_mem_done(eth);
+	} else {
+		reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(idx));
 
-	/* invalidate the IP setting */
-	mtk_w32(eth, (reg_val & ~MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
+		/* invalidate the IP setting */
+		mtk_w32(eth, (reg_val & ~MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
 
-	mtk_w32(eth, ip, MTK_LRO_DIP_DW0_CFG(idx));
+		mtk_w32(eth, ip, MTK_LRO_DIP_DW0_CFG(idx));
 
-	/* validate the IP setting */
-	mtk_w32(eth, (reg_val | MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
+		/* validate the IP setting */
+		mtk_w32(eth, (reg_val | MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
+	}
 }
 
 static void mtk_hwlro_inval_ipaddr(struct mtk_eth *eth, int idx)
@@ -3240,12 +3333,21 @@ static void mtk_hwlro_inval_ipaddr(struct mtk_eth *eth, int idx)
 	const struct mtk_reg_map *reg_map = eth->soc->reg_map;
 	u32 reg_val;
 
-	reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(idx));
+	if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS)) {
+		mtk_hwlro_cfg_mem_clear(eth);
+		reg_val = FIELD_PREP(MTK_GLO_MEM_IDX, MTK_LRO_MEM_IDX);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_ADDR, MTK_LRO_MEM_DIP_BASE + idx);
+		reg_val |= FIELD_PREP(MTK_GLO_MEM_CMD, MTK_GLO_MEM_WRITE);
+		mtk_w32(eth, reg_val, MTK_GLO_MEM_CTRL);
+		mtk_hwlro_cfg_mem_done(eth);
+	} else {
+		reg_val = mtk_r32(eth, MTK_LRO_CTRL_DW2_CFG(idx));
 
-	/* invalidate the IP setting */
-	mtk_w32(eth, (reg_val & ~MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
+		/* invalidate the IP setting */
+		mtk_w32(eth, (reg_val & ~MTK_RING_MYIP_VLD), MTK_LRO_CTRL_DW2_CFG(idx));
 
-	mtk_w32(eth, 0, MTK_LRO_DIP_DW0_CFG(idx));
+		mtk_w32(eth, 0, MTK_LRO_DIP_DW0_CFG(idx));
+	}
 }
 
 static int mtk_hwlro_get_ip_cnt(struct mtk_mac *mac)
@@ -3271,7 +3373,11 @@ static int mtk_hwlro_add_ipaddr_idx(struct net_device *dev, u32 ip4dst)
 
 	/* check for duplicate IP address in the current DIP list */
 	for (i = 1; i <= MTK_HW_LRO_DIP_NUM; i++) {
-		reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+		if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS))
+			reg_val = mtk_hwlro_cfg_mem_get_dip(eth, i);
+		else
+			reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+
 		if (reg_val == ip4dst)
 			break;
 	}
@@ -3283,7 +3389,11 @@ static int mtk_hwlro_add_ipaddr_idx(struct net_device *dev, u32 ip4dst)
 
 	/* find out available DIP index */
 	for (i = 1; i <= MTK_HW_LRO_DIP_NUM; i++) {
-		reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+		if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS))
+			reg_val = mtk_hwlro_cfg_mem_get_dip(eth, i);
+		else
+			reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+
 		if (reg_val == 0UL)
 			break;
 	}
@@ -3306,7 +3416,11 @@ static int mtk_hwlro_get_ipaddr_idx(struct net_device *dev, u32 ip4dst)
 
 	/* find out DIP index that matches the given IP address */
 	for (i = 1; i <= MTK_HW_LRO_DIP_NUM; i++) {
-		reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+		if (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS))
+			reg_val = mtk_hwlro_cfg_mem_get_dip(eth, i);
+		else
+			reg_val = mtk_r32(eth, MTK_LRO_DIP_DW0_CFG(i));
+
 		if (reg_val == ip4dst)
 			break;
 	}
diff --git a/drivers/net/ethernet/mediatek/mtk_eth_soc.h b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
index 8ad271b..a462b17 100644
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.h
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
@@ -180,6 +180,42 @@
 /* PSE Output Queue Threshold Register*/
 #define PSE_OQ_TH(x)		(0x160 + (((x) - 1) << 2))
 
+/* Global Memroy Interface Control Register */
+#define MTK_GLO_MEM_CTRL	0x604
+#define MTK_GLO_MEM_ADDR	GENMASK(19, 0)
+#define MTK_GLO_MEM_IDX		GENMASK(29, 20)
+#define MTK_GLO_MEM_CMD		GENMASK(31, 30)
+#define MTK_GLO_MEM_WRITE	(1)
+#define MTK_GLO_MEM_READ	(2)
+
+/* Global Memory Interface Data Register */
+#define MTK_GLO_MEM_DATA(x)	(0x608 + ((x) * 0x4))
+
+/* Global Memory Interface Index Info */
+#define MTK_LRO_MEM_IDX		(0x4)
+
+/* Global Memory Interface HW LRO CFG Info */
+#define MTK_LRO_MEM_CFG_BASE	(0)
+#define MTK_RING_MAX_AGG_CNT	GENMASK(7, 0)
+#define MTK_RING_OPMODE		GENMASK(9, 8)
+#define MTK_RING_AGE_TIME	GENMASK(15, 0)
+#define MTK_RING_MAX_AGG_TIME_V2	GENMASK(31, 16)
+#define MTK_RING_AUTO_LERAN_MODE_V2	(3)
+
+/* Global Memory Interface HW LRO Data Info */
+#define MTK_LRO_MEM_DATA_BASE	(64)
+#define MTK_LRO_DATA_DIP_IDX	GENMASK(5, 0)
+#define MTK_LRO_DATA_VLD	BIT(26)
+#define MTK_LRO_DATA_DPORT	GENMASK(15, 0)
+#define MTK_LRO_DATA_SPORT	GENMASK(31, 16)
+
+/* Global Memory Interface HW LRO DIP Info */
+#define MTK_LRO_MEM_DIP_BASE	(128)
+#define MTK_LRO_DIP_MODE	GENMASK(1, 0)
+#define MTK_LRO_DIP_INVALID	(0)
+#define MTK_LRO_DIP_IPV4	(1)
+#define MTK_LRO_DIP_IPV6	(2)
+
 /* GDM and CDM Threshold */
 #define MTK_GDM2_THRES		0x1530
 #define MTK_CDMW0_THRES		0x164c
@@ -189,7 +225,8 @@
 #define MTK_CDMM_THRES		0x165c
 
 /* PDMA HW LRO Control Registers */
-#define MTK_HW_LRO_DIP_NUM		(mtk_is_netsys_v3_or_greater(eth) ? 4 : 3)
+#define MTK_HW_LRO_DIP_NUM		(mtk_is_netsys_v3_or_greater(eth) ?	\
+					 (MTK_HAS_CAPS(eth->soc->caps, MTK_GLO_MEM_ACCESS) ? 8 : 4) : 3)
 #define MTK_HW_LRO_RING_NUM		(mtk_is_netsys_v3_or_greater(eth) ? 4 : 3)
 #define MTK_HW_LRO_RING(x)		((x) + (mtk_is_netsys_v3_or_greater(eth) ? 4 : 1))
 #define MTK_HW_LRO_IRQ(x)		((x) + (mtk_is_netsys_v3_or_greater(eth) ? 0 : 1))
@@ -1187,6 +1224,7 @@ enum mkt_eth_capabilities {
 	MTK_MUX_BIT,
 	MTK_INFRA_BIT,
 	MTK_SHARED_SGMII_BIT,
+	MTK_GLO_MEM_ACCESS_BIT,
 	MTK_HWLRO_BIT,
 	MTK_RSS_BIT,
 	MTK_SHARED_INT_BIT,
@@ -1238,6 +1276,7 @@ enum mkt_eth_capabilities {
 #define MTK_MUX			BIT_ULL(MTK_MUX_BIT)
 #define MTK_INFRA		BIT_ULL(MTK_INFRA_BIT)
 #define MTK_SHARED_SGMII	BIT_ULL(MTK_SHARED_SGMII_BIT)
+#define MTK_GLO_MEM_ACCESS	BIT_ULL(MTK_GLO_MEM_ACCESS_BIT)
 #define MTK_HWLRO		BIT_ULL(MTK_HWLRO_BIT)
 #define MTK_RSS			BIT_ULL(MTK_RSS_BIT)
 #define MTK_SHARED_INT		BIT_ULL(MTK_SHARED_INT_BIT)
@@ -1364,8 +1403,8 @@ enum mkt_eth_capabilities {
 		      MTK_GMAC2_2P5GPHY_V2 | MTK_GMAC2_SGMII | MTK_GMAC3_SGMII | \
 		      MTK_MUX_GMAC123_TO_GEPHY_SGMII | MTK_MUX_GMAC2_TO_2P5GPHY | \
 		      MTK_MUX_U3_GMAC23_TO_QPHY | MTK_U3_COPHY_V2 | \
-		      MTK_QDMA | MTK_PDMA_INT | MTK_RSS | \
-		      MTK_RSTCTRL_PPE1)
+		      MTK_QDMA | MTK_PDMA_INT | MTK_RSS | MTK_HWLRO | \
+		      MTK_GLO_MEM_ACCESS | MTK_RSTCTRL_PPE1)
 
 #define MT7988_CAPS  (MTK_36BIT_DMA | MTK_GDM1_ESW | MTK_GMAC1_SGMII | \
 		      MTK_GMAC2_2P5GPHY | MTK_GMAC2_SGMII | MTK_GMAC2_USXGMII | \
-- 
2.45.2

